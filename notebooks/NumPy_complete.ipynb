{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APPF3 | Spring Semester 2020\n",
    "\n",
    "# Storing and Operating on Data with NumPy\n",
    "## Autosave Your Notebook\n",
    "* Activate autosave for your current notebook by using `%autosave`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy: Numerical Python\n",
    "* NumPy: Python library that adds support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n",
    "* NumPy documentation: https://docs.scipy.org/doc/ \n",
    "  * Use your NumPy version number to access the corresponding documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _Note_: We are going to use the `np` alias for the `numpy` module in all the code samples on the following slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy Arrays\n",
    "* Python's vanilla lists are heterogeneous: Each item in the list can be of a different data type\n",
    " * Comes at a cost: Each item in the list must contain its own type info and other information \n",
    " * It is much more efficient to store data in a fixed-type array (all elements are of the same type)\n",
    "* NumPy arrays are homogeneous: Each item in the list is of the same type\n",
    " * They are much more efficient for storing and manipulating data\n",
    "\n",
    "## Creating NumPy Arrays\n",
    "* Use the `np.array()` method to create a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = np.array([0,1,2,3])\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multidimensional NumPy Arrays\n",
    "* _One-dimensional_ array: we only need one coordinate to address a single item, namely an integer index\n",
    "* _Multidimensional_ array: we now need multiple indices to address a single item\n",
    " * For an $n$-dimensional array we need up to $n$ indices to address a single item\n",
    " * We're going to mainly work with two-dimensional arrays in this course, i.e. $n=2$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twodim = np.array([[1,2,3],\n",
    "                   [4,5,6],\n",
    "                   [7,8,9]])\n",
    "twodim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array Indexing\n",
    "* Array indexing for one-dimensional arrays works as usual: `onedim[0]`\n",
    "* Accessing items in a two-dimensional array requires you to specify two indices: `twodim[0,1]`\n",
    "* First index is the row number (here `0`), second index is the column number (here `1`)\n",
    "\n",
    "## Objects in Python\n",
    "* Almost everything in Python is an object, with its properties and methods\n",
    " * For example, a dictionary is an object that provides an `items()` method, which can only be called on a dictionary object (which is the same as a value of the dictionary type, or a dictionary value)\n",
    "* An object can also provide attributes next to methods, which may describe properties of the specific object\n",
    " * For example, for an array object it might be interesting to see how many elements it contains at the moment, so we might want to provide a size attribute storing information about this specific property\n",
    " \n",
    "### NumPy Array Attributes\n",
    "* The type of a NumPy array is `numpy.ndarray` ($n$-dimensional array):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = np.array([0,1,2,3])\n",
    "type(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Useful array attributes\n",
    " * `ndim`: The number of dimensions, e.g. for a two-dimensional array its just 2 \n",
    " * `shape`: Tuple containing the size of each dimension\n",
    " * `size`: The total size of the array (total number of elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(41) # Ensure that the same random numbers are generated each time we run this code\n",
    "x1 = rng.randint(10, size=6) # One-dimensional array\n",
    "x2 = rng.randint(10, size=(3, 4)) # Two-dimensional array\n",
    "print(\"x2 ndim: \", x2.ndim)\n",
    "print(\"x2 shape:\", x2.shape)\n",
    "print(\"x2 size: \", x2.size)\n",
    "print(\"x2 dtype: \", x2.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Arrays from Scratch\n",
    "* NumPy provides a wide range of functions for the creation of arrays:<br>\n",
    "  https://docs.scipy.org/doc/numpy-1.15.4/reference/routines.array-creation.html#routines-array-creation \n",
    " * For example: `np.arange`, `np.zeros`, `np.ones`, `np.linspace`, etc.\n",
    "* NumPy also provides functions to create arrays filled with random data:<br>\n",
    "  https://docs.scipy.org/doc/numpy-1.15.1/reference/routines.random.html\n",
    " * For example: `np.random.random`, `np.random.randint`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(10, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones((3, 5), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.full((3, 5), 3.14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0, 20, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.random((3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(0, 10, (3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy Data Types\n",
    "* Use the keyword `dtype` to specify the data type of the array elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floats = np.array([0,1,2,3], dtype=\"float32\")\n",
    "floats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Overview of available data types: https://docs.scipy.org/doc/numpy-1.15.4/user/basics.types.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array Slicing: One-Dimensional Subarrays\n",
    "* The NumPy slicing syntax follows that of the standard Python list: `x[start:stop:step]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array Slicing: Multidimensional Subarrays\n",
    "* Let `x2` be a two-dimensional NumPy array. Multiple slices are now separated by commas: `x2[start:stop:step, start:stop:step]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2[:2, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2[:3, ::2] # All rows, every other column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2[:, 0] # Select the first column of x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2[1, :] # Select the second row of x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2[1] # Select the second row of x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array Views and Copies\n",
    "* With Python lists, the slices will be _copies_: If we modify the subarray, only the copy gets changed\n",
    "* With NumPy arrays, the slices will be _direct views_: If we modify the subarray, the original array gets changed, too\n",
    " * Very useful: When working with large datasets, we don't need to copy any data (costly operation)\n",
    "* Creating copies: We can use the `copy()` method of a slice to create a copy of the specific subarray\n",
    " * Note: The type of a slice is again `numpy.ndarray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_sub_copy = x2[:2, :2].copy()\n",
    "x2_sub_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_sub_copy[0, 0] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_sub_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping\n",
    "* We can use the `reshape()` method on an NumPy array to actually change its shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.arange(1, 10).reshape((3, 3))\n",
    "print(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For this to work, the size of the initial array must match the size of the reshaped array\n",
    "* _Important_: `reshape()` will return a new view if possible; otherwise, it will be a copy\n",
    " * In case of a view, if you change an entry of the reshaped array, it will also change the initial array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array Concatenation and Splitting\n",
    "* Concatenation, or joining of two or multiple arrays in NumPy can be accomplished through the functions `np.concatenate, np.vstack, and np.hstack`\n",
    " * Join multiple two-dimensional arrays: `np.concatenate([twodim1, twodim2,â€¦], axis=0)`\n",
    "   * A two-dimensional array has two axes: The first running vertically downwards across rows (axis `0`), and the second running horizontally across columns (axis `1`)\n",
    "* The opposite of concatenation is splitting, which is provided by the functions `np.split, np.hsplit` (split horizontally), and `np.vsplit` (split vertically)\n",
    " * For each of these we can pass a list of indices giving the split points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "y = np.array([3, 2, 1])\n",
    "np.concatenate([x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "np.concatenate([grid, grid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate([grid, grid], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "grid = np.array([[9, 8, 7],\n",
    "                 [6, 5, 4]])\n",
    "\n",
    "np.vstack([x, grid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([[99],\n",
    "              [99]])\n",
    "\n",
    "np.hstack([grid, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.arange(16).reshape((4, 4))\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper, lower = np.vsplit(grid, [2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faster Operations Instead of Slow `for` Loops\n",
    "* Looping over arrays to operate on each element can be a quite slow operation in Python\n",
    "* One of the reasons why the for loop approach is so slow is because of the type-checking and function dispatches that must be done at each iteration of the cycle\n",
    " * Python needs to examine the object's type and do a dynamic lookup of the correct function to use for that type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "def compute_reciprocals(values):\n",
    "    output = np.empty(len(values))\n",
    "    for i in range(len(values)):\n",
    "        output[i] = 1.0 / values[i]\n",
    "    return output\n",
    "\n",
    "values = np.random.randint(1, 10, size=5)\n",
    "\n",
    "compute_reciprocals(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_array = np.random.randint(1, 100, size=10000)\n",
    "%timeit compute_reciprocals(big_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy's Universal Functions\n",
    "* NumPy provides very fast, vectorized operations which are implemented via _universal functions_ (ufuncs), whose main purpose is to quickly execute repeated operations on values in NumPy arrays\n",
    " * A _vectorized operation_ is performed on the array, which will then be applied to each element\n",
    "Instead of computing the reciprocal using a for loop, lets do it by using a universal function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit (1.0 / big_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * We can use ufuncs to apply an operation between a scalar and an array, but we can also operate between two arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([4,5,6]) / np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Ufunc Features: Specifying Output and Aggregates\n",
    "* ufuncs provide a few specialized features\n",
    "* We can specify where to store a result (useful for large calculations)\n",
    "* If no `out` argument is provided, a newly-allocated array is returned (can be costly memory-wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random(10)\n",
    "y = np.zeros(10)\n",
    "np.multiply(x,3,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _Reduce_: Repeatedly apply a given operation to the elements of an array until only one single result remains\n",
    " * For example, `np.add.reduce(x)` applies addition to the elements until the one result remains, namely the sum of all elements\n",
    "* _Accumulate_: Almost same as reduce, but also stores the intermediate results of the computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4,5])\n",
    "np.add.reduce(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4,5])\n",
    "np.add.accumulate(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregates\n",
    "* If we want to compute summary statistics for the data in question, aggregates are very useful\n",
    "  * Common summary statistics: mean, standard deviation, median, minimum, maximum, quantiles, etc.\n",
    "* NumPy provides fast built-in aggregation functions for working with arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random(10000)\n",
    "%timeit np.max(x) # NumPy ufunc\n",
    "%timeit max(x)    # Python function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Summing values in an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit np.sum(x) # NumPy ufunc\n",
    "%timeit sum(x)    # Python function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multidimensional Aggregates\n",
    "* By default, each NumPy aggregation function will return the aggregate over the entire array\n",
    "* Aggregation functions take an additional argument specifying the axis along which the aggregate is computed\n",
    " * For example, we can find the minimum value within each column by specifying `axis=0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twodim = np.array([[1,2,3],[0.12, -1, 0.41],[10,9,8]])\n",
    "twodim.min(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Operators as ufuncs\n",
    "* NumPy also implements comparison operators as element-wise ufuncs\n",
    "* The result of these comparison operators is always an array with a Boolean data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([1,2,3]) < 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It is also possible to do an element-by-element comparison of two arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([1,2,3]) < np.array([0,4,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Boolean Arrays: Counting Entries\n",
    "* The `np.count_nonzero()` function will count the number of `True` entries in a Boolean array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = np.array([1,2,3,4,5])\n",
    "np.count_nonzero(nums < 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can also use the `np.sum()` function to accomplish the same. In this case, `True` is interpreted as `1` and `False` as `0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(nums < 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* NumPy also implements bitwise logic operators as element-wise ufuncs\n",
    "* We can use these bitwise logic operators to construct compound conditions (consisting of multiple conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(nums < 2) | (nums > 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean Arrays as Masks\n",
    "* In the previous slides we looked at aggregates computed directly on Boolean arrays\n",
    "* Once we have a Boolean array from lets say a comparison, we can select the entries that meet the condition by using the Boolean array as a _mask_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[3,1,5],[10,32,100],[-1,3,4]])\n",
    "x[x<5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Writing Data with NumPy\n",
    "\n",
    "* We can use the `np.savetxt()` function to save NumPy data to a file\n",
    "* We can use the `np.loadtxt()` function to load data from a file\n",
    "  * *Remember*: We can only store elements of a single type in a NumPy array\n",
    "* Use the shell commands `!ls`, `!pwd`, and `!cd` within our notebook to navigate the file system if necessary\n",
    "\n",
    "### Split-Up Data Example\n",
    "1. We are now first going to generate some data which we will store into multiple files\n",
    "2. In a next step, we are going to read the same split-up data into a NumPy array again. \n",
    "3. **Note**: Please create a `smarthome` folder within the `datasets` folder; we are going to store the files there\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_split_data():\n",
    "    seconds_in_a_day = 24 * 60 * 60 - 1\n",
    "    data_size = (seconds_in_a_day,1)\n",
    "\n",
    "    days = np.arange(1,31)\n",
    "\n",
    "    rng = np.random.RandomState(42)\n",
    "\n",
    "    for day in np.nditer(days):\n",
    "        fridge_temperature = rng.normal(loc=5, scale=2.0, size=data_size)\n",
    "        room_temperature = rng.normal(loc=20, scale=3.0, size=data_size)\n",
    "        outside_temperature = rng.normal(loc=10, scale=2.0, size=data_size)\n",
    "        data = np.concatenate((outside_temperature, room_temperature, fridge_temperature), axis=1) # Concatenate column-wise\n",
    "        # Important: use :02d since it allows us to sort the filenames\n",
    "        np.savetxt(\"./datasets/smarthome/day_{:02d}.txt\".format(day), data, fmt=\"%.4f\", delimiter=\",\", header=\"outside_temperature_celsius, room_temperature_celsius, fridge_temperature_celsius\")\n",
    "        print(\"day #{:02d} done\".format(day))\n",
    "    \n",
    "    print(\"All files have been successfully created!\")\n",
    "        \n",
    "generate_split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def read_split_data():\n",
    "    files_dir = \"./datasets/smarthome\"\n",
    "    files = listdir(files_dir)\n",
    "    files.sort()\n",
    "    \n",
    "    all_data = np.empty((0,3), dtype=np.float32)\n",
    "    \n",
    "    for f in files:\n",
    "        new_data = np.loadtxt(\"{}/{}\".format(files_dir, f), skiprows=1, delimiter=\",\")\n",
    "        all_data = np.vstack((all_data, new_data))\n",
    "        print(\"Done with loading {}\".format(f))\n",
    "        \n",
    "    print(\"Data shape: {}\".format(all_data.shape))\n",
    "\n",
    "read_split_data()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading CSV Data with NumPy\n",
    "* Some CSV data contains a mix between numbers and strings, or might have missing values\n",
    "* We can use the `np.genfromtxt()` function to load mixed data from such a file into a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets play around with the FIFA 2019 player statistics data set and see how we can work with mixed data\n",
    "data = np.genfromtxt(open(\"./datasets/fifa2019_player_statistics.csv\", \"r\"), delimiter=\",\", skip_header=1, missing_values=-1, usecols=(1,2,3,7,8), dtype=[(\"ID\",int),(\"Name\",\"U50\"),(\"Age\",int),(\"Overall rating\",int),(\"Overall potential\",int)])\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
